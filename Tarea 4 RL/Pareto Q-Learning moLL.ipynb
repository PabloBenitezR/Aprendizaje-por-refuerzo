{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipsas\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import mo_gymnasium as mo_gym\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# abbv\n",
    "\n",
    "# acc: acumulada\n",
    "# est: estados\n",
    "# eps: episodios\n",
    "# obj: objetivos\n",
    "# act: acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = mo_gym.make(\"mo-lunar-lander-v3\")\n",
    "num_act = env.action_space.n\n",
    "num_est = 1000\n",
    "alpha = 0.1\n",
    "gamma = 0.99\n",
    "epsilon = 0.1\n",
    "eps = 500\n",
    "num_obj = len(env.reward_range)\n",
    "\n",
    "Q = defaultdict(lambda: np.zeros((num_act, num_obj)))\n",
    "frontera_pareto = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discret(estado):\n",
    "    return tuple(np.round(estado, decimals=1))\n",
    "\n",
    "def selc_accion(estado):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(num_act)\n",
    "    else:\n",
    "        valores = Q[estado]\n",
    "        escal = valores @ np.ones(num_obj) # valores escalarizados\n",
    "        return np.argmax(escal)\n",
    "\n",
    "def act(frontera, nuevo_vec): # Pareto front, imagen del cto de Pareto \n",
    "    no_dominados = []\n",
    "    for vec in frontera:\n",
    "        if np.all(vec >= nuevo_vec) and np.any(vec > nuevo_vec):\n",
    "            return frontera\n",
    "        elif not (np.all(nuevo_vec >= vec) and np.any(nuevo_vec > vec)):\n",
    "            no_dominados.append(vec)\n",
    "    no_dominados.append(nuevo_vec)\n",
    "    return no_dominados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_hist = []\n",
    "\n",
    "for ep in range(eps):\n",
    "    estado, _ = env.reset()\n",
    "    estado = discret(estado)\n",
    "    terminado = False\n",
    "    r_acc = np.zeros(num_obj) # recompensa acc\n",
    "\n",
    "    while not terminado:\n",
    "        accion = selc_accion(estado)\n",
    "        nv_estado, r_vec, fin, tronco, _ = env.step(accion)\n",
    "        nv_estado = discret(nv_estado)\n",
    "        terminado = fin or tronco\n",
    "\n",
    "        mejor_sig = np.max(Q[nv_estado], axis=0)\n",
    "        Q[estado][accion] = (1 - alpha) * Q[estado][accion] + alpha * (r_vec + gamma * mejor_sig)\n",
    "\n",
    "        estado = nv_estado\n",
    "        r_acc = r_acc + r_vec\n",
    "\n",
    "    r_hist.append(r_acc)\n",
    "    front = act(front, r_acc)\n",
    "\n",
    "    if ep % 50 == 0:\n",
    "        print(f\"Episodio {ep}, Recompensa acumulada: {r_acc}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_dicc = np.array(r_hist)\n",
    "plt.plot(r_dicc[:, 0], label='Recompensa 1')\n",
    "plt.plot(r_dicc[:, 1], label='Recompensa 2')\n",
    "plt.title(\"Recompensas por episodio\")\n",
    "plt.xlabel(\"Episodio\")\n",
    "plt.ylabel(\"Recompensas\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "front = np.array(front)\n",
    "plt.scatter(front[:, 0], front[:, 1], color='red')\n",
    "plt.title(\"Frontera de Pareto aproximada\")\n",
    "plt.xlabel(\"Objetivo 1\")\n",
    "plt.ylabel(\"Objetivo 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
