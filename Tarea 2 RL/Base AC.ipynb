{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implememtación base del algoritmo Actor-Crítico\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parámetros\n",
    "alpha_actor = 0.001\n",
    "alpha_critico = 0.01\n",
    "gamma = 0.99 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de características \n",
    "def caracteristicas(estado):\n",
    "    return np.append(estado, 1.0)  \n",
    "\n",
    "# cantidad de características y acciones\n",
    "n_caracteristicas = env.observation_space.shape[0] + 1  \n",
    "n_acciones = env.action_space.n  \n",
    "\n",
    "# pesos iniciales\n",
    "pesos_actor = np.random.rand(n_acciones, n_caracteristicas) * 0.01\n",
    "pesos_critico = np.random.rand(n_caracteristicas) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax \n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / np.sum(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de la política\n",
    "def politica(estado):\n",
    "    x = caracteristicas(estado)\n",
    "    logits = pesos_actor.dot(x)\n",
    "    probas = softmax(logits)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de valor\n",
    "def valor(estado):\n",
    "    x = caracteristicas(estado)\n",
    "    return np.dot(pesos_critico, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de promedio \n",
    "def promedio(datos, vnv=10): # vnv: para el promedio de los episodios\n",
    "    return np.convolve(datos, np.ones(vnv)/vnv, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparámetros\n",
    "n_episodios = 500\n",
    "recompensas_episodios = []       \n",
    "pasos_episodios = []            \n",
    "pasos_totales = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 25: Recompensa Total = 13.0, Pasos Totales = 504\n",
      "Episodio 50: Recompensa Total = 16.0, Pasos Totales = 1136\n",
      "Episodio 75: Recompensa Total = 26.0, Pasos Totales = 1665\n",
      "Episodio 100: Recompensa Total = 15.0, Pasos Totales = 2308\n",
      "Episodio 125: Recompensa Total = 11.0, Pasos Totales = 2841\n",
      "Episodio 150: Recompensa Total = 14.0, Pasos Totales = 3401\n",
      "Episodio 175: Recompensa Total = 25.0, Pasos Totales = 3922\n",
      "Episodio 200: Recompensa Total = 13.0, Pasos Totales = 4459\n",
      "Episodio 225: Recompensa Total = 19.0, Pasos Totales = 4968\n",
      "Episodio 250: Recompensa Total = 10.0, Pasos Totales = 5535\n",
      "Episodio 275: Recompensa Total = 37.0, Pasos Totales = 6187\n",
      "Episodio 300: Recompensa Total = 52.0, Pasos Totales = 6900\n",
      "Episodio 325: Recompensa Total = 18.0, Pasos Totales = 7370\n",
      "Episodio 350: Recompensa Total = 19.0, Pasos Totales = 7966\n",
      "Episodio 375: Recompensa Total = 15.0, Pasos Totales = 8596\n",
      "Episodio 400: Recompensa Total = 16.0, Pasos Totales = 9400\n",
      "Episodio 425: Recompensa Total = 26.0, Pasos Totales = 10081\n",
      "Episodio 450: Recompensa Total = 12.0, Pasos Totales = 10591\n",
      "Episodio 475: Recompensa Total = 27.0, Pasos Totales = 11108\n",
      "Episodio 500: Recompensa Total = 16.0, Pasos Totales = 11546\n"
     ]
    }
   ],
   "source": [
    "for episodio in range(n_episodios):\n",
    "    estado, _ = env.reset()  \n",
    "    terminado = False\n",
    "    recompensa_total = 0\n",
    "    \n",
    "    while not terminado:\n",
    "        x = caracteristicas(estado)\n",
    "        probas = politica(estado)\n",
    "        accion = np.random.choice(n_acciones, p=probas)\n",
    "        sig_estado, recompensa, terminado, trunco, _ = env.step(accion)\n",
    "        terminado = terminado or trunco  \n",
    "        recompensa_total = recompensa_total + recompensa\n",
    "        pasos_totales = pasos_totales + 1\n",
    "\n",
    "        # valor actual y el que sigue\n",
    "        v = valor(estado)\n",
    "        v_siguiente = valor(sig_estado)\n",
    "        \n",
    "        # (TD error)\n",
    "        error_td = recompensa + gamma * v_siguiente * (1 - int(terminado)) - v\n",
    "        \n",
    "        # actualizar al actor\n",
    "        pesos_critico = pesos_critico + alpha_critico * error_td * x\n",
    "\n",
    "        gradiente = -probas[:, None] * x[None, :]\n",
    "        gradiente[accion] = gradiente[accion] + x  \n",
    "        pesos_actor = pesos_actor + alpha_actor * error_td * gradiente\n",
    "        \n",
    "        estado = sig_estado\n",
    "\n",
    "    recompensas_episodios.append(recompensa_total)\n",
    "    pasos_episodios.append(pasos_totales)\n",
    "    \n",
    "    if (episodio+1) % 25 == 0: # cada N episodios\n",
    "        print(f\"Episodio {episodio+1}: Recompensa Total = {recompensa_total}, Pasos Totales = {pasos_totales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Política (pesos) del actor:\n",
      "[[ 0.02902616 -0.00932751 -0.01167272  0.03453811  0.04412833]\n",
      " [-0.02206137  0.01888128  0.01325435 -0.02058301 -0.03905536]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Política (pesos) del actor:\")\n",
    "print(pesos_actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
